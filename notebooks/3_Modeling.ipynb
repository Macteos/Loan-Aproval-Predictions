{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/macteos/Documents/Code/Kaggle Projects/Housing Prices/.venv/lib/python3.12/site-packages/sklearn/experimental/enable_hist_gradient_boosting.py:16: UserWarning: Since version 1.0, it is not needed to import enable_hist_gradient_boosting anymore. HistGradientBoostingClassifier and HistGradientBoostingRegressor are now stable and can be normally imported from sklearn.ensemble.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.metrics import median_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib.patches import ConnectionPatch\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('../data/raw/train.csv')\n",
    "df_test = pd.read_csv('../data/raw/test.csv')\n",
    "\n",
    "df_train = df_train.drop(columns=['id'])\n",
    "df_test = df_test.drop(columns=['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df_train, df_test):\n",
    "    label_enc = LabelEncoder()\n",
    "    label_cols = ['person_home_ownership', 'loan_grade', 'cb_person_default_on_file']\n",
    "    for col in label_cols:\n",
    "        df_train[col] = label_enc.fit_transform(df_train[col])\n",
    "        df_test[col] = label_enc.transform(df_test[col])\n",
    "    df_train = pd.get_dummies(df_train, columns=['loan_intent'], drop_first=True)\n",
    "    df_test = pd.get_dummies(df_test, columns=['loan_intent'], drop_first=True)\n",
    "    target_col = 'loan_status'\n",
    "    train_columns = df_train.drop(columns=[target_col]).columns\n",
    "    df_test = df_test.reindex(columns=train_columns, fill_value=0)\n",
    "    return df_train, df_test\n",
    "\n",
    "df_train_processed, df_test_processed = preprocess_data(df_train, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((58645, 16), (39098, 15))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train = df_train_processed\n",
    "df_test = df_test_processed\n",
    "\n",
    "df_train.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_train['loan_status']\n",
    "df_train = df_train.drop(['loan_status'],axis=1)\n",
    "X = df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaled_train_data = df_train\n",
    "scaled_test_data = df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall AUC (LGBMClassifier): 0.9562025439130687\n"
     ]
    }
   ],
   "source": [
    "lgb_params = {\n",
    "    'objective': 'binary',\n",
    "        'n_estimators': 3000,\n",
    "        'metric': 'binary_logloss',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'random_state': 42,\n",
    "        'learning_rate':0.0322942967545754,\n",
    "        'num_leaves': 24,\n",
    "        'max_depth': 15,\n",
    "        'min_data_in_leaf': 25,\n",
    "        'feature_fraction': 0.6236144085285287,\n",
    "        'bagging_fraction': 0.9596685778433888,\n",
    "        'bagging_freq': 3,\n",
    "        'verbose' : -1\n",
    "}\n",
    "\n",
    "n_splits = 5\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "lgbm_predictions = np.zeros(len(scaled_train_data))\n",
    "lgbm_true_labels = np.zeros(len(scaled_train_data))\n",
    "lgbm_test_predictions = np.zeros(len(scaled_test_data))\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(scaled_train_data, y)):\n",
    "    X_train, X_val = scaled_train_data.iloc[train_idx], scaled_train_data.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "    lgbm_model = LGBMClassifier(**lgb_params)\n",
    "    lgbm_model.fit(X_train, y_train,\n",
    "                   eval_set=[(X_val, y_val)],\n",
    "                   eval_metric='auc')\n",
    "\n",
    "    lgbm_fold_preds = lgbm_model.predict_proba(X_val)[:, 1]\n",
    "    lgbm_fold_test_preds = lgbm_model.predict_proba(scaled_test_data)[:, 1]\n",
    "    lgbm_predictions[val_idx] = lgbm_fold_preds\n",
    "    lgbm_true_labels[val_idx] = y_val\n",
    "    lgbm_test_predictions += lgbm_fold_test_preds / n_splits\n",
    "\n",
    "overall_metric_lgbm = roc_auc_score(lgbm_true_labels, lgbm_predictions)\n",
    "print(\"Overall AUC (LGBMClassifier):\", overall_metric_lgbm)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
